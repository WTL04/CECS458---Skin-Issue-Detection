{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78758b0-c9f0-4153-9cb8-4414b99e82ff",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3179781-e7e4-4357-a22e-9b3f4681d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "ROOT = \"./face_skin_dataset/\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (512, 512)\n",
    "AUTOTUNE = tf.data.AUTOTUNE # automatically tunes CPU usage\n",
    "\n",
    "train_annotations = pd.read_csv(os.path.join(ROOT, \"train\", \"_annotations.csv\"))\n",
    "val_annotations = pd.read_csv(os.path.join(ROOT, \"valid\", \"_annotations.csv\"))\n",
    "test_annotations = pd.read_csv(os.path.join(ROOT, \"test\",  \"_annotations.csv\"))\n",
    "\n",
    "# create path/to/img lists\n",
    "def make_paths(df, split):\n",
    "    return [os.path.join(ROOT, split, fname) for fname in df[\"filename\"]]\n",
    "\n",
    "train_paths = make_paths(train_annotations, \"train\")\n",
    "val_paths = make_paths(val_annotations,   \"valid\")\n",
    "test_paths = make_paths(test_annotations,  \"test\")\n",
    "\n",
    "# creating labels lists\n",
    "class_names = sorted(train_annotations[\"class\"].unique())\n",
    "num_classes = len(class_names)\n",
    "name2id = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "train_labels = train_annotations[\"class\"].map(name2id).astype(\"int32\")\n",
    "val_labels   = val_annotations[\"class\"].map(name2id).astype(\"int32\")\n",
    "test_labels  = test_annotations[\"class\"].map(name2id).astype(\"int32\")\n",
    "\n",
    "# create a tensorFlow dataset with ( path/to/img, label) pairs\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7721ceb-e935-4b5e-9c3c-acb0a8ce431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    image = tf.io.read_file(path) # read image from disk\n",
    "    image = tf.image.decode_jpeg(image, channels=3) # decode jpeg image\n",
    "    image = tf.image.resize(image, IMG_SIZE) # ensure images 512 x 512\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # normalize image pixel scale from [0, 255] to [0, 1]\n",
    "    return image, label\n",
    "\n",
    "# apply load_image function to each image in dataset using .map function\n",
    "# shuffle images and batch in sets of 32\n",
    "def pipeline(paths, labels, training):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=min(len(paths), 1000), reshuffle_each_iteration=True)\n",
    "    ds = ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = pipeline(train_paths, train_labels, True)\n",
    "val_ds = pipeline(val_paths, val_labels, False)\n",
    "test_ds = pipeline(test_paths, test_labels, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a99084-1177-4015-8ecf-9338291bf6a1",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275753ec-bd9d-48ab-8d8a-aac76916b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        # convolution 1\n",
    "        layers.Conv2D(filters=64, kernel_size=7, strides=2, padding=\"same\", input_shape=(512,512,3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "\n",
    "        # pool 1\n",
    "        layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "\n",
    "        # convolution 2\n",
    "        layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        # convolution 3\n",
    "        layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        # pool 2\n",
    "        layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "        \n",
    "        # convolution 3     \n",
    "        layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "\n",
    "        # convolution 4\n",
    "        layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "\n",
    "        # pool 3        \n",
    "        layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "\n",
    "        # fully connected layers\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2591b4-67fb-40ff-b2fd-3c3937de8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba5d8c-ce0a-4be9-9de3-62aa37eed4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8a2b1-e7c9-44f7-8697-765da88e32bb",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0f2f3-9ab8-4f70-b0ea-2fe25e204b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4dffa0-02b6-4b2a-b39a-cbf7fb9e6132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
