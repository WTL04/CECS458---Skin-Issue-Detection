{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c3b489-c89d-4d10-a7e7-39547fb6e971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "Setup complete âœ… (16 CPUs, 15.5 GB RAM, 176.3/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344582f7-d7c5-4852-97a1-101f6551d3ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b01c75-a263-4904-a8f4-7b7bd8fe8c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.228 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/home/wtl04/coding/uni/cecs458/skindetect/face_skin_yolo/data.yaml, epochs=30, time=None, patience=100, batch=32, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs, name=notebook_train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/notebook_train14\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2123401  ultralytics.nn.modules.head.Detect           [19, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11,142,953 parameters, 11,142,937 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/notebook_train14', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/wtl04/coding/uni/cecs458/skindetect/face_skin_yolo/train/labels.cache... 2283 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2283/2283 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 6160, len(boxes) = 14290. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wtl04/coding/uni/cecs458/skindetect/face_skin_yolo/val/labels.cache... 125 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 327, len(boxes) = 688. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/notebook_train14/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000435, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/notebook_train14\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      5.02G      1.725       1.32      1.261         49        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:17<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.474      0.419      0.338       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      4.75G      1.821      1.509      1.315         68        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:17<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.443      0.398      0.332      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      4.83G      1.862      1.592      1.351         64        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.442      0.293      0.263      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      4.79G      1.909      1.681      1.377         40        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.338      0.331      0.243     0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      5.21G      1.932      1.667      1.386         38        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.459      0.338      0.288      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      4.73G      1.914      1.621       1.37         61        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.401      0.339      0.283      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      4.94G      1.879      1.587      1.362         36        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.504      0.275      0.273      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         5G       1.86      1.514      1.345         96        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.482       0.24      0.232        0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      4.71G      1.829      1.486       1.33         49        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.479        0.3      0.287      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      4.81G      1.815      1.435      1.324         43        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.415      0.296      0.254       0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      4.85G       1.78      1.374      1.288         75        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.481      0.372      0.314      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      4.73G      1.747      1.321      1.286         67        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.449      0.337       0.31      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      5.15G      1.729      1.294      1.274         72        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.506      0.352      0.294      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      4.93G      1.706      1.242      1.257         53        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688       0.49      0.383      0.311      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      4.73G      1.671      1.203      1.236         81        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.465      0.373      0.305      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      4.85G      1.641      1.157      1.227         75        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.551      0.284      0.292      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      4.99G      1.626      1.133      1.213         40        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.423      0.374      0.306      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      4.94G      1.607      1.104      1.204         59        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.449      0.313      0.293      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      4.76G      1.574      1.068      1.195         53        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.447       0.34        0.3       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      5.02G      1.548      1.033       1.18         48        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688       0.43       0.38      0.309      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      4.95G      1.531     0.9976      1.166         73        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.519      0.405      0.337       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      5.25G      1.488     0.9559      1.146         62        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.452      0.347      0.323      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      5.03G      1.477     0.9393      1.144         54        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.523      0.345      0.302      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      5.02G      1.476     0.9198      1.128         47        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.415      0.377      0.289      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      5.03G      1.437       0.89      1.121         41        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.551      0.328      0.297      0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      4.79G      1.394     0.8655      1.105         58        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.479      0.347      0.306      0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      4.74G      1.378     0.8438      1.097         68        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.449      0.372      0.313      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      4.82G       1.36     0.8292      1.083         86        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.444      0.357      0.314      0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30       4.8G      1.345      0.824      1.084         38        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.436      0.393      0.314      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         5G      1.336     0.8114      1.078         55        512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:16<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.426      0.392      0.314      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 0.161 hours.\n",
      "Optimizer stripped from runs/notebook_train14/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/notebook_train14/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/notebook_train14/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "Model summary (fused): 168 layers, 11,132,937 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        125        688      0.473      0.419      0.339       0.15\n",
      "                     3         18         48      0.354      0.438      0.334      0.121\n",
      "           Dark Circle         17         33      0.844      0.727      0.884      0.422\n",
      "           Dark circle          2          4      0.655      0.955      0.787      0.359\n",
      "                Eyebag          3          5          1          0     0.0209    0.00654\n",
      "             acne scar          4         17      0.225      0.471      0.187     0.0994\n",
      "             blackhead          1          2          1          0     0.0152    0.00377\n",
      "            blackheads         23         52      0.465      0.673      0.592      0.239\n",
      "               freckle         20         38      0.511      0.549      0.528      0.225\n",
      "               nodules          7         13      0.135      0.231      0.132     0.0398\n",
      "               papules         25         88       0.35      0.534      0.389      0.135\n",
      "              pustules          8         13      0.167      0.692      0.181     0.0679\n",
      "           skinredness          7         15      0.814      0.467      0.546      0.299\n",
      "              vascular          3          9      0.598      0.556       0.54      0.276\n",
      "             whitehead          1          1          0          0          0          0\n",
      "            whiteheads         24         65      0.239      0.277      0.188     0.0752\n",
      "               wrinkle         20        285      0.218      0.133     0.0941      0.034\n",
      "Speed: 0.1ms preprocess, 2.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/notebook_train14\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  9, 11, 12, 13, 14, 15, 16, 17, 18])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7bbf4c29ec10>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        6.76500677e-04, 3.38250338e-04, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.88760189e-02, 9.43800944e-03, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        6.66666667e-01, 6.66666667e-01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.58749057e-04, 7.93745287e-05, 0.00000000e+00],\n",
       "       [5.00000000e-01, 5.00000000e-01, 5.00000000e-01, ...,\n",
       "        3.24774859e-04, 1.62387430e-04, 0.00000000e+00],\n",
       "       [5.00000000e-01, 5.00000000e-01, 5.00000000e-01, ...,\n",
       "        8.82864445e-05, 4.41432222e-05, 0.00000000e+00]], shape=(15, 1000)), 'Recall', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.09318182, 0.09318182, 0.12498175, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.44137931, 0.44137931, 0.51704065, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.25      , 0.25      , 0.33778086, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02946317, 0.02946317, 0.03955625, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.04686914, 0.04686914, 0.05627185, ..., 0.        , 0.        ,\n",
       "        0.        ]], shape=(16, 1000)), 'Confidence', 'F1'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.04927885, 0.04927885, 0.0675569 , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.28571429, 0.28571429, 0.35249523, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.14285714, 0.14285714, 0.20321079, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01497462, 0.01497462, 0.02021868, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.02475738, 0.02475738, 0.03011533, ..., 1.        , 1.        ,\n",
       "        1.        ]], shape=(16, 1000)), 'Confidence', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.85416667, 0.85416667, 0.83333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96969697, 0.96969697, 0.96969697, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.90769231, 0.90769231, 0.90769231, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.43859649, 0.43859649, 0.42807018, ..., 0.        , 0.        ,\n",
       "        0.        ]], shape=(16, 1000)), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.16901682962467313)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([0.12125052, 0.42223675, 0.35941071, 0.00654118, 0.09937176,\n",
       "       0.00377211, 0.23876905, 0.15017229, 0.15017229, 0.22496862,\n",
       "       0.15017229, 0.03979593, 0.13479413, 0.06792278, 0.29876341,\n",
       "       0.2759458 , 0.        , 0.07521542, 0.03399853])\n",
       "names: {0: '3', 1: 'Dark Circle', 2: 'Dark circle', 3: 'Eyebag', 4: 'acne scar', 5: 'blackhead', 6: 'blackheads', 7: 'dark spot', 8: 'darkspot', 9: 'freckle', 10: 'melasma', 11: 'nodules', 12: 'papules', 13: 'pustules', 14: 'skinredness', 15: 'vascular', 16: 'whitehead', 17: 'whiteheads', 18: 'wrinkle'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.4733396776401104), 'metrics/recall(B)': np.float64(0.4189041318068906), 'metrics/mAP50(B)': np.float64(0.33861765237683894), 'metrics/mAP50-95(B)': np.float64(0.15017229376332136), 'fitness': np.float64(0.16901682962467313)}\n",
       "save_dir: PosixPath('runs/notebook_train14')\n",
       "speed: {'preprocess': 0.12244033813476562, 'inference': 2.3154163360595703, 'loss': 6.103515625e-05, 'postprocess': 1.1485614776611328}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root = Path('./face_skin_yolo').resolve() # root dataset path\n",
    "\n",
    "model.train(\n",
    "    data=str((root/'data.yaml')),\n",
    "    epochs=30,\n",
    "    imgsz=512,\n",
    "    batch=32,\n",
    "    project='runs',\n",
    "    name='notebook_train',\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9097349f-4c03-4b73-8bb9-9bd455476af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1+cu128 CPU (Intel Core(TM) i5-14400F)\n",
      "Model summary (fused): 168 layers, 11,132,937 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/notebook_train14/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 23, 5376) (21.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim==0.1.34'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m This environment is externally managed\n",
      "\u001b[31mâ•°â”€>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 1/2 failed: Command 'pip install --no-cache-dir \"onnxslim==0.1.34\" ' returned non-zero exit status 1.\n",
      "Retry 2/2 failed: Command 'pip install --no-cache-dir \"onnxslim==0.1.34\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âŒ Command 'pip install --no-cache-dir \"onnxslim==0.1.34\" ' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m This environment is externally managed\n",
      "\u001b[31mâ•°â”€>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "W1114 09:35:01.812000 2304 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 10 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 10).\n",
      "Failed to convert the model to the target version 10 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wtl04/coding/uni/cecs458/inclass/regularization/tf_venv/lib/python3.13/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "        func=_partial_convert_version, model=model\n",
      "    )\n",
      "  File \"/home/wtl04/coding/uni/cecs458/inclass/regularization/tf_venv/lib/python3.13/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "  File \"/home/wtl04/coding/uni/cecs458/inclass/regularization/tf_venv/lib/python3.13/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        proto, target_version=self.target_version\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/wtl04/coding/uni/cecs458/inclass/regularization/tf_venv/lib/python3.13/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:65: adapter_lookup: Assertion `false` failed: No Adapter To Version $17 for Resize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 1 of general pattern rewrite rules.\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 4.6s, saved as 'runs/notebook_train14/weights/best.onnx' (42.6 MB)\n",
      "\n",
      "Export complete (4.9s)\n",
      "Results saved to \u001b[1m/home/wtl04/coding/uni/cecs458/skindetect/runs/notebook_train14/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/notebook_train14/weights/best.onnx imgsz=512  \n",
      "Validate:        yolo val task=detect model=runs/notebook_train14/weights/best.onnx imgsz=512 data=/home/wtl04/coding/uni/cecs458/skindetect/face_skin_yolo/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/notebook_train14/weights/best.onnx'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"onnx\", keras=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850297b-adc2-47b6-9080-c148b6ca8e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
